Input :
| name | address   | email         | floor | resources |
|------|-----------|---------------|-------|-----------|
| A    | Bangalore | A@gmail.com   | 1     | CPU       |
| A    | Bangalore | A1@gmail.com  | 1     | CPU       |
| A    | Bangalore | A2@gmail.com  | 2     | DESKTOP   |
| B    | Bangalore | B@gmail.com   | 2     | DESKTOP   |
| B    | Bangalore | B1@gmail.com  | 2     | DESKTOP   |
| B    | Bangalore | B2@gmail.com  | 1     | MONITOR   |


Output:
| name | most_visited_floor | total_visits | used_resources    |
|------|--------------------|--------------|-------------------|
| A    | 1                  | 3            | CPU,DESKTOP       |
| B    | 2                  | 3            | DESKTOP,MONITOR   |


SQL
-------------------------------------------------------

create table entries ( 
name varchar(20),
address varchar(20),
email varchar(20),
floor int,
resources varchar(10));

insert into entries 
values ('A','Bangalore','A@gmail.com',1,'CPU'),('A','Bangalore','A1@gmail.com',1,'CPU'),('A','Bangalore','A2@gmail.com',2,'DESKTOP')
,('B','Bangalore','B@gmail.com',2,'DESKTOP'),('B','Bangalore','B1@gmail.com',2,'DESKTOP'),('B','Bangalore','B2@gmail.com',1,'MONITOR');

select * from entries;
+------+-----------+--------------+-------+-----------+
| name | address   | email        | floor | resources |
+------+-----------+--------------+-------+-----------+
| A    | Bangalore | A@gmail.com  |     1 | CPU       |
| A    | Bangalore | A1@gmail.com |     1 | CPU       |
| A    | Bangalore | A2@gmail.com |     2 | DESKTOP   |
| B    | Bangalore | B@gmail.com  |     2 | DESKTOP   |
| B    | Bangalore | B1@gmail.com |     2 | DESKTOP   |
| B    | Bangalore | B2@gmail.com |     1 | MONITOR   |
+------+-----------+--------------+-------+-----------+

with most_visited_floor as 
(select name,floor,rank() over(partition by name order by count(Floor) desc)  as rank_floor from entries group by name,floor)
select * from most_visited_floor;
+------+-------+------------+
| name | floor | rank_floor |
+------+-------+------------+
| A    |     1 |          1 |
| A    |     2 |          2 |
| B    |     2 |          1 |
| B    |     1 |          2 |
+------+-------+------------+

with most_visited_floor as 
(select name,floor,count(floor),rank() over(partition by name order by count(Floor) desc)  as rank_floor from entries group by name,floor),
total_visit_table as
(select name,count(floor) as total_visits,group_concat(distinct resources) as used_resources from entries group by name)
select mf.name,mf.rank_floor as most_visited_floor,tv.total_visits,tv.used_resources from most_visited_floor  as mf join total_visit_table as tv on mf.name = tv.name
where most_visited_floor = 1;
+------+--------------------+--------------+-----------------+
| name | most_visited_floor | total_visits | used_resources  |
+------+--------------------+--------------+-----------------+
| A    |                  1 |            3 | CPU,DESKTOP     |
| A    |                  2 |            3 | CPU,DESKTOP     |
| B    |                  1 |            3 | DESKTOP,MONITOR |
| B    |                  2 |            3 | DESKTOP,MONITOR |
+------+--------------------+--------------+-----------------+




--------------------------------------------------------------------------------------------------
Pyspark
--------------------------------------------------------------------------------------------------

# Initialize SparkSession
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("MostVisitedFloor").getOrCreate()

# Create DataFrame
data = [
    ('A','Bangalore','A@gmail.com',1,'CPU'),
    ('A','Bangalore','A1@gmail.com',1,'CPU'),
    ('A','Bangalore','A2@gmail.com',2,'DESKTOP'),
    ('B','Bangalore','B@gmail.com',2,'DESKTOP'),
    ('B','Bangalore','B1@gmail.com',2,'DESKTOP'),
    ('B','Bangalore','B2@gmail.com',1,'MONITOR')
]

columns = ["name", "address", "email", "floor", "resources"]
df = spark.createDataFrame(data,columns)
df.show()
+----+---------+------------+-----+---------+
|name|  address|       email|floor|resources|
+----+---------+------------+-----+---------+
|   A|Bangalore| A@gmail.com|    1|      CPU|
|   A|Bangalore|A1@gmail.com|    1|      CPU|
|   A|Bangalore|A2@gmail.com|    2|  DESKTOP|
|   B|Bangalore| B@gmail.com|    2|  DESKTOP|
|   B|Bangalore|B1@gmail.com|    2|  DESKTOP|
|   B|Bangalore|B2@gmail.com|    1|  MONITOR|
+----+---------+------------+-----+---------+

from pyspark.sql.functions import *
agg_df = df.groupBy(col('name')).agg(count(col('floor')).alias('total_visits'),concat_ws(",",collect_set(col("resources"))).alias('used_resources'))

from pyspark.sql.window import Window
visited_floor_df = df.groupBy("name","floor").agg(count("*").alias("count_visited_floor"))
windowSpec = Window.partitionBy("name").orderBy(col("count_visited_floor").desc())
most_visited_floor_df = visited_floor_df.withColumn("rank",rank().over(windowSpec)).filter(col("rank")==1).select("name",col("floor").alias("most_visited_floor"))

final_df = most_visited_floor_df.join(agg_df,on = "name",how = "inner")
final_df.show()
+----+------------------+------------+---------------+
|name|most_visited_floor|total_visits| used_resources|
+----+------------------+------------+---------------+
|   A|                 1|           3|    DESKTOP,CPU|
|   B|                 2|           3|DESKTOP,MONITOR|
+----+------------------+------------+---------------+


